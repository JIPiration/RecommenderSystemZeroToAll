{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems - Neural Collaborative Filtering\n",
    "> Demo\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- hide: true\n",
    "- categories: [demo, neural networks, deep learning, recommender systems, paper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dependencies and run `tensorboard` in the background:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install tensorflow lightfm pandas\\n\\n%load_ext tensorboard\\n!tensorboard --logdir 2020-09-11-neural_collaborative_filter/logs &\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install tensorflow lightfm pandas\n",
    "\n",
    "%load_ext tensorboard\n",
    "!tensorboard --logdir 2020-09-11-neural_collaborative_filter/logs &\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import lightfm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy import sparse\n",
    "from tensorboard import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.5.0-dev20210122\n",
      "LightFM version: 1.16\n",
      "Pandas version: 1.1.4\n",
      "Numpy version: 1.19.2\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"LightFM version: {lightfm.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "![](https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/2020-09-11-neural_collaborative_filter/matrix_factorization_with_alpha.png \"Credit: https://developers.google.com/machine-learning/recommendation/collaborative/basics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix:\n",
      "[[5 3 4 3 3 5 4 0 5 3]\n",
      " [4 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0 4 4 0]\n",
      " [0 0 0 5 0 0 5 5 5 4]\n",
      " [0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0]\n",
      " [4 0 0 4 0 0 0 0 4 0]]\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "data = fetch_movielens(min_rating=3.0)\n",
    "\n",
    "print(\"Interaction matrix:\")\n",
    "print(data[\"train\"].toarray()[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 74627 stored elements in COOrdinate format>,\n",
       " 'test': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 7893 stored elements in COOrdinate format>,\n",
       " 'item_features': <1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1682 stored elements in Compressed Sparse Row format>,\n",
       " 'item_feature_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
       "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
       "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
       " 'item_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
       "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
       "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix:\n",
      "[[1 1 1 1 1 1 1 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 1 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 0]]\n",
      "\n",
      "Ratings:\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#collapse\n",
    "for dataset in [\"test\", \"train\"]:\n",
    "    data[dataset] = (data[dataset].toarray() > 0).astype(\"int8\")  # astype(\"int8\")을 통해 조건값 이진화.\n",
    "    \n",
    "# Make the ratings binary\n",
    "print(\"Interaction matrix:\")\n",
    "print(data[\"train\"][:10, :10])\n",
    "\n",
    "print(\"\\nRatings:\")\n",
    "unique_ratings = np.unique(data[\"train\"])\n",
    "print(unique_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def wide_to_long(wide: np.array, possible_ratings: List[int]) -> np.array:\n",
    "    \"\"\"Go from wide table to long.\n",
    "    :param wide: wide array with user-item interactions\n",
    "    :param possible_ratings: list of possible ratings that we may have.\"\"\"\n",
    "    \n",
    "    def _get_ratings(arr: np.array, rating: int) -> np.array:\n",
    "        \"\"\"Generate long array for the rating provided\n",
    "        :param arr: wide array with user-item interactions\n",
    "        :param rating: the rating that we are interested\"\"\"\n",
    "        idx = np.where(arr == rating)\n",
    "        return np.vstack(\n",
    "            (idx[0], idx[1], np.ones(idx[0].size, dtype=\"int8\") * rating)  # \n",
    "        ).T  # .T: 행과열 전치\n",
    "    \n",
    "    long_arrays = []\n",
    "    for r in possible_ratings:\n",
    "        long_arrays.append(_get_ratings(wide, r))\n",
    "        \n",
    "    return np.vstack(long_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_train = wide_to_long(data[\"train\"], unique_ratings)\n",
    "df_train = pd.DataFrame(long_train, columns=['user_id', 'item_id', 'interaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    7,    0],\n",
       "       [   0,   10,    0],\n",
       "       [   0,   19,    0],\n",
       "       ...,\n",
       "       [ 942, 1187,    1],\n",
       "       [ 942, 1227,    1],\n",
       "       [ 942, 1329,    1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All interactions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586121</th>\n",
       "      <td>942</td>\n",
       "      <td>1043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586122</th>\n",
       "      <td>942</td>\n",
       "      <td>1073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586123</th>\n",
       "      <td>942</td>\n",
       "      <td>1187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586124</th>\n",
       "      <td>942</td>\n",
       "      <td>1227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586125</th>\n",
       "      <td>942</td>\n",
       "      <td>1329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1586126 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  interaction\n",
       "0              0        7            0\n",
       "1              0       10            0\n",
       "2              0       19            0\n",
       "3              0       20            0\n",
       "4              0       26            0\n",
       "...          ...      ...          ...\n",
       "1586121      942     1043            1\n",
       "1586122      942     1073            1\n",
       "1586123      942     1187            1\n",
       "1586124      942     1227            1\n",
       "1586125      942     1329            1\n",
       "\n",
       "[1586126 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "print(\"All interactions:\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only positive interactions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1511499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511500</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511501</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511502</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511503</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  interaction\n",
       "1511499        0        0            1\n",
       "1511500        0        1            1\n",
       "1511501        0        2            1\n",
       "1511502        0        3            1\n",
       "1511503        0        4            1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "print(\"Only positive interactions:\")\n",
    "df_train[df_train[\"interaction\"] > 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model (Neural Collaborative Filtering)\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/murilo-cunha/inteligencia-superficial/master/images/2020-09-11-neural_collaborative_filter/ncf_all_with_alpha.png\" width=\"70%\" url=\"https://developers.google.com/machine-learning/recommendation/collaborative/basics\" description=\"Fonte: https://developers.google.com/machine-learning/recommendation/collaborative/basics\" /> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Multiply,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "def create_ncf(\n",
    "    number_of_users: int,\n",
    "    number_of_items: int,\n",
    "    latent_dim_mf: int = 4,\n",
    "    latent_dim_mlp: int = 32,\n",
    "    reg_mf: int = 0,\n",
    "    reg_mlp: int = 0.01,\n",
    "    dense_layers: List[int] = [8, 4],\n",
    "    reg_layers: List[int] = [0.01, 0.01],\n",
    "    activation_dense: str = 'relu',\n",
    ") -> keras.Model:\n",
    "    \n",
    "    # input layer\n",
    "    user = Input(shape=(), dtype='int32', name='user_id')\n",
    "    item = Input(shape=(), dtype='int32', name='item_id')\n",
    "    \n",
    "    # embedding layers\n",
    "    mf_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "    mf_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "    \n",
    "    mlp_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "    \n",
    "    mlp_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "    \n",
    "    # MF vector\n",
    "    mf_user_latent = Flatten()(mf_user_embedding(user))\n",
    "    mf_item_latent = Flatten()(mf_item_embedding(item))\n",
    "    mf_cat_latent = Multiply()([mf_user_latent, mf_item_latent])\n",
    "\n",
    "    # MLP vector\n",
    "    mlp_user_latent = Flatten()(mlp_user_embedding(user))\n",
    "    mlp_item_latent = Flatten()(mlp_item_embedding(item))\n",
    "    mlp_cat_latent = Concatenate()([mlp_user_latent, mlp_item_latent])\n",
    "    \n",
    "    mlp_vector = mlp_cat_latent\n",
    "    \n",
    "    # build dense layers for model\n",
    "    for i in range(len(dense_layers)):\n",
    "        layer = Dense(\n",
    "            dense_layers[i],\n",
    "            activity_regularizer=l2(reg_layers[i]),\n",
    "            activation=activation_dense,\n",
    "            name=\"layer%d\" % i,\n",
    "        )\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "        \n",
    "    predict_layer = Concatenate()([mf_cat_latent, mlp_vector])\n",
    "    \n",
    "    result = Dense(\n",
    "        1, activation=\"sigmoid\", kernel_initializer=\"lecun_uniform\", name=\"interaction\"\n",
    "    )\n",
    "    \n",
    "    output = result(predict_layer)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[user, item],\n",
    "        outputs=[output],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"neural_collaborative_filtering\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_user_embedding (Embedding)  (None, 32)           30176       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mlp_item_embedding (Embedding)  (None, 32)           53824       item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 32)           0           mlp_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 32)           0           mlp_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mf_user_embedding (Embedding)   (None, 4)            3772        user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mf_item_embedding (Embedding)   (None, 4)            6728        item_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 64)           0           flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 4)            0           mf_user_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 4)            0           mf_item_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer0 (Dense)                  (None, 8)            520         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 4)            0           flatten_20[0][0]                 \n",
      "                                                                 flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 4)            36          layer0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8)            0           multiply_5[0][0]                 \n",
      "                                                                 layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "interaction (Dense)             (None, 1)            9           concatenate_10[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 95,065\n",
      "Trainable params: 95,065\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# collapse\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "n_users, n_items = data[\"train\"].shape\n",
    "ncf_model = create_ncf(n_users, n_items)\n",
    "\n",
    "ncf_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"acu\"),\n",
    "    ],\n",
    ")\n",
    "ncf_model._name = \"neural_collaborative_filtering\"\n",
    "ncf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    targets: List[str],\n",
    "    val_split: float = 0.1,\n",
    "    batch_size: int = 512,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"Make TensorFlow dataset from Pandas DataFrame.\n",
    "    :param df: input DataFrame - only contains features and target(s)\n",
    "    :param targets: list of columns names corresponding to targets\n",
    "    :param val_split: fraction of the data that should be used for validation\n",
    "    :param batch_size: batch size for training\n",
    "    :param seed: random seed for shuffling the data - setting to `None` will not shuffle the data\"\"\"\n",
    "    \n",
    "    n_val = round(df.shape[0] * val_split)\n",
    "    if seed:\n",
    "        # shuffle all the rows\n",
    "        x = df.sample(frac=1, random_state=seed).to_dict(\"series\")\n",
    "    else:\n",
    "        x = df.to_dict(\"series\")\n",
    "    y = dict()\n",
    "    for t in targets:\n",
    "        y[t] = x.pop(t)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    \n",
    "    ds_val = ds.take(n_val).batch(batch_size)\n",
    "    ds_train = ds.skip(n_val).batch(batch_size)\n",
    "    return ds_train, ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation datasets\n",
    "ds_train, ds_val = make_tf_dataset(df_train, [\"interaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2789/2789 [==============================] - 14s 5ms/step - loss: 0.1244 - tp: 5683.0000 - fp: 2214.0000 - tn: 1358200.0000 - fn: 61416.0000 - accuracy: 0.9554 - precision: 0.7196 - recall: 0.0847 - acu: 0.9159 - val_loss: 0.1185 - val_tp: 1247.0000 - val_fp: 525.0000 - val_tn: 150560.0000 - val_fn: 6281.0000 - val_accuracy: 0.9571 - val_precision: 0.7037 - val_recall: 0.1656 - val_acu: 0.9210\n",
      "CPU times: user 30.4 s, sys: 2.46 s, total: 32.9 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define logs and callbacks\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=0\n",
    ")\n",
    "\n",
    "train_hist = ncf_model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_test = wide_to_long(data[\"train\"], unique_ratings)\n",
    "df_test = pd.DataFrame(long_test, columns=[\"user_id\", \"item_id\", \"interaction\"])\n",
    "ds_test, _ = make_tf_dataset(df_test, [\"interaction\"], val_split=0, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.28 s, sys: 306 ms, total: 6.59 s\n",
      "Wall time: 5.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ncf_predictions = ncf_model.predict(ds_test)\n",
    "df_test[\"ncf_predictions\"] = ncf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "      <th>ncf_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  interaction  ncf_predictions\n",
       "0        0        7            0         0.483398\n",
       "1        0       10            0         0.468876\n",
       "2        0       19            0         0.115457\n",
       "3        0       20            0         0.125516\n",
       "4        0       26            0         0.106007"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# sanity checks - stop execution if we have low standard deviation (all recommendations are the same)\n",
    "std = df_test.describe().loc[\"std\", \"ncf_predictions\"]\n",
    "if std < 0.01:\n",
    "    raise ValueError(\"Model predictions have standard deviation of less than le-2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural collaborative filtering predictions\n",
      "[[0.6269704  0.24987572 0.1468502  0.49421766]\n",
      " [0.2256749  0.02604404 0.02385423 0.0362916 ]\n",
      " [0.19684681 0.03824714 0.03633711 0.03165561]\n",
      " [0.1689327  0.02127731 0.01980689 0.01723003]\n",
      " [0.56245416 0.2204996  0.1208525  0.31617355]\n",
      " [0.6136544  0.12170559 0.07536039 0.46111798]\n",
      " [0.6823194  0.37174204 0.23828226 0.6701757 ]\n",
      " [0.4547332  0.05517426 0.02830127 0.10933998]\n",
      " [0.19163734 0.01153988 0.00932038 0.01495835]\n",
      " [0.56063217 0.10945806 0.07458898 0.39636242]]\n"
     ]
    }
   ],
   "source": [
    "#collapse\n",
    "data[\"ncf_predictions\"] = df_test.pivot(\n",
    "    index=\"user_id\", columns=\"item_id\", values=\"ncf_predictions\"\n",
    ").values\n",
    "print(\"Neural collaborative filtering predictions\")\n",
    "print(data[\"ncf_predictions\"][:10, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At K = 5, we have a precision of 0.09841 and a recall of 0.05879\n"
     ]
    }
   ],
   "source": [
    "precision_ncf = tf.keras.metrics.Precision(top_k=TOP_K)\n",
    "recall_ncf = tf.keras.metrics.Recall(top_k=TOP_K)\n",
    "\n",
    "precision_ncf.update_state(data[\"test\"], data[\"ncf_predictions\"])\n",
    "recall_ncf.update_state(data[\"test\"], data[\"ncf_predictions\"])\n",
    "print(\n",
    "    f\"At K = {TOP_K}, we have a precision of {precision_ncf.result().numpy():.5f} and a recall of {recall_ncf.result().numpy():.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At K = 5, we have a precision of 0.10880 and a recall of 0.06499\n",
      "CPU times: user 853 ms, sys: 45.9 ms, total: 899 ms\n",
      "Wall time: 784 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LightFM model\n",
    "norm = lambda x: (x - np.min(x)) / np.ptp(x)\n",
    "lightfm_model = LightFM(loss=\"warp\")\n",
    "lightfm_model.fit(sparse.coo_matrix(data[\"train\"]), epochs=N_EPOCHS)\n",
    "\n",
    "lightfm_predictions = lightfm_model.predict(\n",
    "    df_test[\"user_id\"].values, df_test[\"item_id\"].values\n",
    ")\n",
    "df_test[\"lightfm_predictions\"] = lightfm_predictions\n",
    "wide_predictions = df_test.pivot(\n",
    "    index=\"user_id\", columns=\"item_id\", values=\"lightfm_predictions\"\n",
    ").values\n",
    "data[\"lightfm_predictions\"] = norm(wide_predictions)\n",
    "\n",
    "# compute the metrics\n",
    "precision_lightfm = tf.keras.metrics.Precision(top_k=TOP_K)\n",
    "recall_lightfm = tf.keras.metrics.Recall(top_k=TOP_K)\n",
    "precision_lightfm.update_state(data[\"test\"], data[\"lightfm_predictions\"])\n",
    "recall_lightfm.update_state(data[\"test\"], data[\"lightfm_predictions\"])\n",
    "print(\n",
    "    f\"At K = {TOP_K}, we have a precision of {precision_lightfm.result().numpy():.5f} and a recall of {recall_lightfm.result().numpy():.5f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jipiration",
   "language": "python",
   "name": "jipiration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
